# MySQL基础

[TOC]



## 一. 基础

### 1.1 MySQL存储引擎有哪些？有什么特点。

MySQL核心在于插件式存储引擎，存储引擎是基于表，开发者可以按照自己意愿进行开发，不同存储引擎具备不同的特点，包含InnoDB、MyISAM等。

- InnoDB存储引擎

InnoDB支持事务，强制要求有主键，支持外键约束，高并发、大数据量（通过分库分表、读写分离），高可用（主备切换）。

现在版本（5.5.8开始）默认存储引擎为InnoDB，使用比较成熟，常用。

- MyISAM存储引擎

不支持事务，不支持外键，支持全文索引，索引文件与数据文件分开，索引文件位于内存中，查询性能较好，适用于多查询的需求。

为表锁设计，并发写，性能差一些。

适用于报表系统，一次导入，后面都是大量查询场景。



什么是全文索引



### 1.2 MySQL数据库支持锁类型有哪些？

包含表锁（MyISAM）、页锁，行锁（InnoDB）。



什么是页锁



### 1.3 InnoDB支持哪些锁？

**InnoDB的行锁**分为共享锁（S）和排他锁（X）

共享锁：允许事务读取一行数据，即允许多个事务加共享锁，来读取同一条数据，但是其它事务不能来写这行数据。

排他锁：允许事务删除或更新一条数据，即只允许一个事务来写这行数据，其它事务可以进行读。



**InnoDB的意向锁，即表级别锁**，事务能够获得多行的排他锁或者共享锁。

当执行insert、update 、delete命令时，会自动给所修改行加入行级排他锁。select不会加锁。

InnoDB锁用来保证，一行数据，当有事务进行修改时，其它人不能修改，只能进行读。



> 意向锁是一种`不与行级锁冲突表级锁`，这一点非常重要。意向锁分为两种：
>
> - 意向共享锁
>
>   （intention shared lock, IS）：事务有意向对表中的某些行加共享锁（S锁）
>
>   ```
>   -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。
>   SELECT column FROM table ... LOCK IN SHARE MODE;
>   ```
>
> - 意向排他锁
>
>   （intention exclusive lock, IX）：事务有意向对表中的某些行加排他锁（X锁）
>
>   ```
>   -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。
>   SELECT column FROM table ... FOR UPDATE;
>   ```
>
> 即：`意向锁是有数据引擎自己维护的，用户无法手动操作意向锁`，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。
>
> 
>
> 意向锁作用：
>
> - 如果没有意向锁的话，则需要遍历所有整个表判断是否有行锁的存在，以免发生冲突
>
> - 如果有了意向锁，只需要判断该意向锁与即将添加的表级锁是否兼容即可。因为意向锁的存在代表了，有行级锁的存在或者即将有行级锁的存在。因而无需遍历整个表，即可获取结果
>
>   
>
> [详解 MySql InnoDB 中意向锁的作用](https://juejin.cn/post/6844903666332368909)



查询操作select，默认不会主动加锁，因为InnoDB默认实现了可重复读，采用了MVCC机制，

多个事务进行读取数据，不会出现重复。

但是也可以进行手动加锁。

手动加共享锁   select * from table where id = 1 lock in share mode

手动加排他锁  select * from table where id = 1 for update 

此时其它事务会进行等待。



**间隙锁**

幻读的问题存在是因为新增或者更新操作，这时如果进行范围查询的时候（加锁查询），会出现不一致的问题，这时使用不同的行锁已经没有办法满足要求，需要对一定范围内的数据进行加锁，间隙锁就是解决这类问题的。锁的就是两个值之间的空隙。

在可重复读隔离级别下，数据库是通过行锁和间隙锁共同组成的（next-key lock），来实现的。



间隙锁是在可重复读隔离级别下才会生效的

当使用唯一索引来搜索唯一行的语句时，不需要间隙锁定。

没有建立索引或者是非唯一索引时，则语句会产生间隙锁。

**间隙的范围**

根据检索条件向下寻找最靠近检索条件的记录值A作为左区间，向上寻找最靠近检索条件的记录值B作为右区间，即锁定的间隙为（A，B）。





### 1.4 MySQL 中乐观锁与悲观锁

悲观锁：每次操作都担心其它操作会同步修改，都进行加锁select * from table where id = 1 for update 

乐观锁：比较乐观，不进行加锁，在修改数据前，先查询一次，接着再执行update操作，update是比较下版本号，是否还是前一次select到的版本号，如果是就进行修改。如果一样就进行修改，然后版本号加1，否则就不进行更新，然后重写进行查询再更新。



一般不建议使用悲观锁，存在死锁风险。

### 1.5 InnoDB中死锁？如何解决？

**死锁概念**

事务A持有行1的锁，想要去获取事务B持有的行2的锁，同时事务B持有行2的锁，想去获取事务A持有行1的锁，事务A与事务B互相等待，造成死锁。

**解决死锁**

1） 采用超时，当互相等待时，一方超时，直接回滚，另一方可以继续执行

2）查看日志，找到对应死锁位置，分析代码避免



### 1.5 MySQL中索引的原理是什么？

索引的目的是为了提高查询效率。

MySQL中最常用索引为B+树索引，其底层数据结构是B+树。B+树索引分为聚簇索引和非聚簇索引。

**B+树索引查询流程**   

首先根据索引查找到所查找数据行所在的页，然后数据库把页中数据读入内存中，再在内存中进行查找，最终拿到需要查找的数据。并不是通过索引直接查找到所需要查找的元素。



为什么使用B树	

Ｂ树出现是因为磁盘IO。IO操作的效率很低，那么，当在大量数据存储中，查询时我们不能一下子将所有数据加载到内存中，只能逐一加载磁盘页，每个磁盘页对应树的节点。造成大量磁盘IO操作（最坏情况下为树的高度）。平衡二叉树由于树深度过大而造成磁盘IO读写过于频繁，进而导致效率低下。
所以，为了减少磁盘IO的次数，就你必须降低树的深度，将“瘦高”的树变得“矮胖”。



### 1.8 MyISAM的索引实现原理？

MyISAM存储引擎，索引文件与数据文件分开，索引文件位于内存中。索引文件依据B+ 树存储，索引key对应值为地址，对应数据文件中数据。查找时，先从内存中，查找索引文件找到地址，再从数据文件中查找对应数据。





### 1.9 B+树数据结构有什么特点？

B+树是通过二叉查找树，再由平衡二叉树，B树演化而来，是一种平衡查找树，是多路查找树。

B+树中，记录节点按照键值的大小顺序放在同一层叶子节点上。如下B+树，高度为2，每页可存放4条记录（指树的分叉树）。所有记录都在叶子节点，顺序存放。

当出入元素28时，由于LeafPage和IndexPage都没有满，直接插入即可。

![](.\img\01_01.png)

**B+树特点** 

- B+树索引中对应节点存入的元素都在叶子节点上，即内部节点25,50,75只存储索引key，不存储元素值data。（这样可以存储更多的节点元素，可以使得B+树比B树更加矮胖，查询时IO次数更少）

- 同时在叶子节点上，加了顺序访问指针，便于范围查找。
- 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。

- 叶子节点点本身依关键字的大小自小而大顺序链接。

- B+树总会保持平衡，因此在插入元素时，会进行拆分页。



**B+树查询过程**

单元素查询，B+树自顶向下逐层查找，最终找到匹配的叶子节点。

范围查询，找到下限的节点位置，通过链表指针进行遍历



采用B+树

- 非叶子节点不存data，只存储索引（冗余），可以放更多的索引。
- 非叶子节点包含所有索引字段
- 叶子节点用指针连接，提高区间访问的性能，便于范围查询
- 插入或者删除元素都会导致节点发生裂变反应，来保持平衡



![在这里插入图片描述](https://img-blog.csdnimg.cn/20200820093629917.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyMjIzNTY1,size_16,color_FFFFFF,t_70#pic_center)

[Mysql索引B+树，索引优化](https://blog.csdn.net/qq_32223565/article/details/108116736)



### 1.10 B+树和B-树有什么区别？

1）B+树的非叶子节点只存储键值信息，因此可以放更多的索引，B-树是都存储键值信息的，

2）B+树的所有叶子节点之间存在指针，便于范围查找

3）B+树的节点只存储索引key值，具体信息的地址存在于叶子节点的地址中。



**B+树的优势：**

1.单一节点存储更多的元素，使得查询的IO次数更少。

2.所有查询都要查找到叶子节点，查询性能稳定。

3.所有叶子节点形成有序链表，便于范围查询。



### 1.11 聚簇索引和非聚簇索引有什么区别？

B+树索引分为聚集索引和非聚集索引。

**聚集索引**  InnoDB，数据文件就是索引文件，默认使用主键作为索引，称为聚簇索引。

InnoDB中要求必须有主键

如果采用非主键值作为索引，此时索引中元素对应的value值为主键值，查找时，会先在对应非主键值的索引中，查找到元素对应的主键，然后再在数据文件的聚集索引中，查找到对应元素。

因此，一般InnoDB中，都建议采用自增值作为主键。自增值，在插入元素时，只需要顺序插入新节点，避免了树的旋转再进行拆分页。

**非聚集索引** MyISAM，数据文件与索引文件分开。索引文件中存储的值为对应数据文件中的地址。

一张表只能有一个聚簇索引。一般情况下主键就是默认的聚簇索引

一个表可以有不止一个非聚簇索引。

[什么是索引页和数据页](https://juejin.cn/post/7030607153173889055)

### 1.12 什么情况适合使用索引？

1）创建索引需要占用磁盘空间，索引在本质上通过空间换取时间，会增加磁盘消耗

2）频繁修改索引，会降低性能，同时索引越多，需要修改的越多

因此，不建议创建过多索引，一张表，建立1-3个索引。

选择哪些值作为索引

需要查看该字段，在总行数中的占比，不能是该字段，多数都为相同值，导致使用完索引查询后，还有大量数据需要进行过滤，那么与不创建索引，就几乎没有差别。因此，每个值，几乎都不太一样，那么使用索引，效率就会更高



### 1.13 索引使用规则？

当需要使用多个参数进行查询时，如SQL语句select * from db where id1=1 and  id2=2 and id3=3  时，可以使用联合索引。

联合索引将多个字段组合为一个联合索引，如id1,id3，id3

1）全列匹配

三个条件都能使用索引

2）最左前缀匹配

联合索引，最左边一个或连续几个可以使用索引

3）最左前缀匹配，中间值没匹配

如使用到了联合索引的第一列，和第三列，但是第二列没有使用到索引。

select * from db where id1=1 and id3=3

此时先使用第一列索引进行查找，然后进行扫描过滤一次，找到id3=3。

4) 没有最左匹配

select * from db where id2=3

此时也不会走索引

5) 前缀匹配

如果是like，只能是like 'XX%'才能使用索引

select * from db where id1 =1 and id2='22%'

6) 范围列查询

范围查询（>=  <=）操作，是能够利用查询，但是范围之后操作就不会走索引了

select * from db where id1>=1 and id2=2

7) 包含函数

如果使用了函数，那一列将不使用索引

select * from db where id1=1 and 函数(id2)=2

id1会使用索引，但是函数不会使用索引

[联合索引存储方式和最左匹配](https://www.cnblogs.com/xuwc/p/14007766.html)


### 1.14 事务包含哪几个特性？

四个特性ACID

原子性（atomicity）：事务里的一系列操作，要么一起执行成功，如果某个操作执行失败，则全部会失败，事务执行会失败；

一致性（consistency）：指数据一致性，执行事务是对数据库状态从一种状态转变为另一种状态，不能在执行事务前后，数据库完整性出现变化。比如，事务对数据表中的主键ID进行修改，事务执行成功或者回滚后，主键ID被修改，不再唯一，导致数据库状态发生变化。

隔离性（isolation）：指多个事务之间的操作不能互相影响，同一时间，只允许一个事务请求同一数据；

持久性（durability）：指事务执行完成后，能够持久有效，不能过段时间，自己消失掉或者又恢复为以前。



AID一起带来了C。

### 1.15 MySQL支持哪几种事务隔离级别？

**读未提交（read-uncommitted）**：一个事务可以读取到另一个事务里未提交的数据

**读已提交（也称不可重复读）（read-committed）**：一个事务在读取另一个事务里修改到的数据，需要等到另一个事务将数据修改提交后，才能读取到。例如：事务A读取到表中某个数据值为A，当事务B对该数据进行修改，修改为B，此时再提交，那么事务A再读取该数据，得到的值为B，即能够读取到其它事务已提交的数据，不能读取到未提交的数据。相对于读未提交，稍显严格一点。（能够解决脏读）

**可重复读（repeatable-read）**：一个事务开始后，读取某个数据值为A，无论读取多少次都为A，即使其它事务对该值进行了修改，无论修改是否提交。（能够解决不可重复读）

**串行化（serializable）**：多个事务执行，串行化执行，一个事务执行，需要等到上个事务执行完成，才能执行，不能并行执行。（能够解决幻读）



### 1.16 事务隔离级别能够解决哪些问题？

事务的执行存在脏读、不可重复读和幻读的问题。

**脏读**：事务A读取到了另一个事务B里修改的值，未提交，最终事务B回滚了，导致事务A读取到数据为脏数据

**不可重复读**：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致

**幻读**：针对插入，一个事务A将表中所有行的某个字段修改为A，此时另一个事务B插入了一条数据并提交，数据中的某个字段并没有被修改过。导致事务A的执行出现了幻觉，修改不完全。

不同事务隔离级别能够解决的问题

| 事务隔离级别                 | 脏读 | 不可重复读 | 幻读 |
| ---------------------------- | ---- | ---------- | ---- |
| 读未提交（read-uncommitted） | 是   | 是         | 是   |
| 不可重复读（read-committed） | 否   | 是         | 是   |
| 可重复读（repeatable-read）  | 否   | 否         | 是   |
| 串行化（serializable）       | 否   | 否         | 否   |

InnoDB存储引擎，默认事务隔离级别为可重复读（repeatable-read）。



### 1.17 不同事务隔离级别的底层实现原理是什么？

MySQL使用的MVCC（多版本并发控制）实现可重复读。

通过在每行记录后面保存两个隐藏列来实现。隐藏列一个用来存储记录创建时间，一个用来记录记录删除时间，即通过这两个值来表示这条记录属于哪个版本。此处存储的值并不为时间，为对应事务的ID。每次更新该记录中数据时，会新增记录，但是主键还是一致的，只是保存到不同版本中，当进行查询时，返回不同版本的数据即可。

当事务ID为18的事务，进行查询时，只会返回隐藏列中创建事务ID小于等于18的数据，从而保证不同事务重复多次读数据一致。

```
// 如表中数据
id   name  age  创建事务ID  删除事务ID
1    tom   12    18
1    tom   20    20
```

MVCC只在可重复读和不可重复读两个隔离级别中使用，通过该种方式，可以不用加锁操作，查询性能更好，但是需要额外保存多个版本的数据，带来了存储空间的开销。

读未提交，只需要每次都读取最新数据，不需要进行版本控制。

串行化通过对所有读取行加锁实现。



### 1.18 MySQL索引类型

- 普通**索引**   基本的索引类型，值可以为空，没有唯一性的限制。
- 唯一**索引**   索引列的所有值都只能出现一次
- 主键**索引**   主键是一种唯一性索引
- 组合**索引**
- 全文**索引**



### 1.19 MySQL索引失效情况？

1. 如果条件中有or，即使其中有条件带索引也不会使用
2. 使用模糊查询，like  直接以%开头
3. 不符合组合查询最左匹配原则
4. 



## 二 提高

### 2.1 一条SQL语句是如何执行的？











## 三 数据库分库分表

### 3.1 为什么要分库分表？使用哪些中间件进行分库分表？各具备哪些优缺点？

单表700万，超过1000万，最好分库分表

假如存在一个单机数据库，表中3000万数据，高峰8000个请求，每天新增数据量120万

#### 单击MySQL存在问题原因： 

1. MySQL单机，磁盘容量不够
2. MySQL单机，扛不住高并发
3. MySQL单表数据量大，SQL慢

#### 分库之后优点

   	1. MySQL从单机，分为3个库，那么可以承受的并发增加了3倍
   	  	2. 3个库，每个库容量降为了1/3，磁盘使用率降低
   	     	3. 原来一个单表3000万数据，查询一个SQL 3s，现在拆分之后，每个表1000万数据，SQL查询时间也缩短

#### 分库分表有哪些中间件

数据库中间件，在数据分发时，能够确定将数据分发至哪个数据库中。

如下使用较多

- sharding-jdbc 

  client层方案，支持分库分表，读写分离，分布式id生成，柔性事务（最大努力推送，TCC事务）

  不需要额外去部署，但是如果升级需要每个使用者都升级

- mycat

  proxy层方案，也挺好

  需要部署，进行运维

### 3.2 如何进行水平拆分？垂直拆分？

- 垂直拆分（一般在数据库设计时进行）

  将一个表中多个字段进行拆分，将常用字段拆分到一个表中

- 水平拆分（常用）

  每个表中放一部分数据，比如1000万表进行拆分

  可以使用唯一ID进行hash取模（11%3）分到不同的库，下不同的表上面。

  或者根据时间，如何1月数据写在一个表，2月写在另外一个表



两种方式

- 一种按照range来分：每个表存储一段连续的数据，可以是按照时间。较少使用。

  因为热点数据，通常是新插入数据，请求量还是高，会集中在这一个表上。

  扩容方便

- 一种按照hash分发（常用），平均分配每个库的数据量和请求压力。

  扩容不方便，需要进行数据迁移

 

### 3.3 如何设计不停机把系统向未分库分表动态切换到分库分表上？

- 方案1: 停机维护进行动态迁移

  停机后，编写独立程序，从原有数据库表中进行数据读取，通过数据库中间件，写向数据库。

  完成后，重新启动，使用数据库中间件进行数据库操作。

  缺点：需要停机

- 方案2：不停机，双写方案

  数据请求后，进行双写，单库单表写入，分库分表也写入

  再通过后台数据迁移程序，将单库单表中数据，通过数据库中间件写入到分库分表中。写入时需要先从分库分表中，进行读取，判断数据是否已存在，如果存在，需要比较哪边数据较新。

  完成后，判断两边数据是否一模一样。

  后台程序可以连续多跑一段时间，如果分库不再写入数据，就可以了。

  然后修改程序，不再使用单库单表。

  

### 3.4 如何设计可以动态扩容的分库分表方案？

- 方案1：停机扩容

  使用代码，进行扩容

  （通常单库单表迁移到分库分表上，数据量都不大，如果是动态进行扩容，此时数据量会比较大）

- 方案2：

  设计时，使用32个库，每个库32张表，共1024张表。基本中小互联网公司项目够用。

  每个库能够正常承载并发量1000/s，那么32个库的承载写，32*1000=32000，并发写。

  如果每个库承载1500的写并发，32*1500=4800的写并发，接近5w/s的写入并发，可以再加上一个MQ，进行削峰，每秒写入MQ 8w条数据，每秒消费5w条数据。

  1024张表，每张表500w条数据，MySQL可以放50亿条数据。

  通常一台数据库服务器，可以承载2000/s以内的写并发。

  如果需要承载8000/s的写并发。

  可以一台数据库服务器有32个库，可以分成两个数据库服务器，一个数据库服务器16个库，一个16个库，将数据进行迁移。进行扩容。

  路由规则

  通过ordId对32取模找到，对应库，然后再对32取模，找到对应的表。

  此时最大可以扩展到32个数据库服务器，一个数据库服务器一个库，一个库32个表，还能再按表进行扩容



### 3.5 分库分表之后，id主键如何处理？

- 方案1：创建一个全局一个主键库（适用于并发不高，数据量大）

  创建一个生成主键的全局库，插入数据时，先将数据插入主键库，然后拿这个ID再去其它库里插入，保证了唯一

- 方案2：使用uuid

  不太适合数据库主键名，太长32位，入库性能差。

  **不使用UUID原因**

  1）UUID生成速率低下

  Java的UUID依赖于SecureRandom.nextBytes方法，而SecureRandom又依赖于操作系统提供的随机数源，在Linux系统下，它的默认依赖是/dev/random，而这个源是阻塞的。最可怕的是，这个nextBytes方法还是一个synchronized方法，也就是说，如果多线程调用UUID，生成速率不升反降。

  测试结果：在一台64线程的服务器上，调用UUID.randomUUID方法，生成一千万个uuid平均耗时在130s，tps不到8w

  2）UUID主键在innodb中会引发性能问题

  a. innodb中的主键索引也是聚集索引，如果插入的数据是顺序的，那么b+树的叶子基本都是满的，缓存也可以很好的发挥作用。如果插入的数据是完全无序的，那么叶子节点会频繁分裂，缓存也基本无效了。这会减少tps

  b. uuid占用的空间较大

   3）UUID完全没有意义，如果有一个主键是全局自增的，那么数据排列顺序就是数据的插入顺序

- 方案3：系统时间

  可能重复，可以使用系统时间再拼接ID

- 方案4： snowflake算法

  雪花算法，分布式ID，结构

  ![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/NtO5sialJZGovUVwFkfA0yRdCYoer9mqxdkKsBd5aD96r6ygicrXlKjwmsIBCZpF4rrkUM7FR1U1zZdL4yjEF1Fw/640?wx_fmt=png)

  SnowFlake所生成的ID一共分成四部分：

  1.第一位

  占用1bit，其值始终是0，表示正数

  2.时间戳

  占用41bit，精确到毫秒，总共可以容纳约140年的时间。

  3.工作机器id

  占用10bit，其中高位5bit是数据中心ID（datacenterId），低位5bit是工作节点ID（workerId），做多可以容纳1024个节点。

  类似于机房ID，机器ID

  4.序列号

  占用12bit，这个值在同一毫秒同一节点上从0开始不断累加，最多可以累加到4095。

  

  同一毫秒的ID数量 = 1024 X 4096 = 4194304

  这个数字在绝大多数并发场景下都是够用的。

  **实现方案**

  1.获得单一机器的下一个序列号，使用Synchronized控制并发，而非CAS的方式，是因为CAS不适合并发量非常高的场景。

  2.如果当前毫秒在一台机器的序列号已经增长到最大值4095，则使用while循环等待直到下一毫秒。

  3.如果当前时间小于记录的上一个毫秒值，则说明这台机器的时间回拨了，抛出异常。但如果这台机器的系统时间在启动之前回拨过，那么有可能出现ID重复的危险。
  **优点**

  1.生成ID时不依赖于DB，完全在内存生成，高性能高可用。

  2.ID呈趋势递增，后续插入索引树的时候性能较好。

  **缺点**

  依赖于系统时钟的一致性。如果某台机器的系统时钟回拨，有可能造成ID冲突，或者ID乱序。




### 3.6 如何实现MySQL读写分离？如何解决MySQL主从同步的延时问题？

#### 什么是MySQL读写分离		

读写分离：往主库里写数据时，会同步到从库，读取数据时，从从库里去读。因此，降低了数据库的请求压力。

#### 如何实现MySQL读写分离？主从复制延迟问题产生原因

MySQL主从复制

MySQL里存在binlog日志，每个增删改查的操作，会改变数据的操作，除了更新数据的操作，对这个增删改操作会写入一个日志文件，记录这个日志的文件，称为binlog日志。

主库和从库建立连接后，主库中工作线程进行写入时，一方面写入数据，另一方面记录binlog日志，此时IO线程会通与从库进行通信，将主库的binlog日志，同步给从库的relay日志里，从库的SQL线程会根据日志进行数据更新，从而保持同步。

从库读取binlog日志，写入relay日志，应该日志变更到本地数据，为一个串行化过程。在5.6后，从库支持多线程从主库去读取binlog日志。但瓶颈在于将数据写入到数据库过程为单线程。

因此，会出现从库数据会比主库要慢，出现主从同步延迟。通常主库写数据达到1000/s，从库延时可能又几ms，并发写达到2000/s，延时可能会有几十ms。如果大于4000/s，6000/s，8000/s，会有几秒。

#### 主从复制数据丢失问题？半同步复制、并行复制原理

假如主库突然挂了，导致主库数据未完全同步到从库中。

可以采用semi-sync半同步复制，指主库写入binlog日志之后，会强制将数据同步到从库，从库将日志写入到本地的relaylog之后，接着返回一个ack给主库，主库收到至少一个库的ack之后，才会认为写操作完成。

并行复制，从数据库，会开启多个SQL线程，从relaylog里读一个库的日志，进行重放，缓解主从并发。



通常在读远远多于写的情况下，多考虑使用主从复制。

#### 解决主从复制延时问题方法

存在问题，主库并发写达到2000/s，有几十ms延时，在从从库里读数据时，读取不到

对于延时比较严重问题，可以采用如下步骤解决

1. 分库，将一个主库分为4个主库，每个主库的写并发500/s，此时主从复制延迟可以降低
2. 开启MySQL支持的并行复制，多个库并行复制。并行复制是库级别，但是如果并发写入都集中在某个表，那么并行复制也没什么效果。
3. 写代码时，避免插入更新数据后，立马就进行查询的操作
4. 如果必须要读，可以强制从主库里读取。（不太建议，有点违背读写分离）



## 四 调优

### 4.1 MySQL如何调优？

通常情况下，SQL查询最好为单表查询，多表处理逻辑使用Java代码处理，此时只用考虑查询耗时问题。如果查询慢，可以添加索引，同时在查询时用到该索引，从而提高效率。可以通过查看MySQL的执行计划，查看慢SQL是否使用到了索引。此种只为基础的回答方式。

执行计划

explain select * from table



**数据选型：**首先是数据选型方面进行优化，选取最适用的字段属性，数据的表越小，查询越快 

**范式应用：**合理使用范式和反范式 

**存储引擎的选择：**如果该数据库读操作较多，存储引擎选择MyISAM，如果是写操作多，选择innodb 

**主键选择：**代理主键 

**执行计划explain：**使用explain+sql测试sql语句执行情况，然后优化sql语句 

1.  注意的关键字：type关键字，通常达到range级别，最好是ref，而ref最好是一个常数。 

 **索引优化：** 

1.  尽量在主键上添加使用索引 
2.  利用覆盖索引、索引下推机制，注意组合索引的匹配原则， 
3.  尽量使用唯一索引，避免使用普通索引 

**查询优化：**这个应该被包含在执行计划中，但是个人觉得还是拆出来，其实我们在写的时候就该注意sql的效率，explain执行计划只是验证 

1.  优化数据访问，避免查询中出现筛选大量数据，可以通过limit限制； 
2.  避免select * from table这种全表扫描的语句 
3.  如果业务没有特殊规定数据，那么就尽量避免使用UNION，可以考虑UNION-ALL替换，因为后者不会过滤重复数据，效率高于UNION



[MySQL索引原理及慢查询优化](https://tech.meituan.com/2014/06/30/mysql-index.html)



### 4.2 通常数据库索引使用方案

尽量使用单表来增删改查，降低SQL复杂度

通常再配上主键索引和少数几个联合索引，基本就够用了。

尽量不要使用SQL来进行计算，函数，子查询等。使用Java代码去实现逻辑。









